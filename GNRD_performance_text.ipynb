{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import all the libraries we need\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#Get a list of all the folders. The name of the folder is also the id number for the data package. Each folder\n",
    "#contains the text of the pdf as a txt file and the json result from GNRD.\n",
    "packages = []\n",
    "annotation_file = open('annotator_results.txt', 'r')\n",
    "next(annotation_file)\n",
    "for line in annotation_file:\n",
    "    line = line.strip()\n",
    "    row = line.split('\\t')\n",
    "    data_package = row[1]\n",
    "    if data_package in packages:\n",
    "        pass\n",
    "    else:\n",
    "        packages.append(data_package)\n",
    "#packages = next(os.walk('pdf_text'))[1]\n",
    "#packages.remove('133')\n",
    "print(len(packages))\n",
    "'110' in packages\n",
    "#Should output '215' and 'True' if working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed successfully\n"
     ]
    }
   ],
   "source": [
    "#Iterate over all the folders and grab the json results from each. Use the csv to get a list of unique\n",
    "#names that GNRD found. From the json, get important metadata, like total words, and figure out which names\n",
    "#were updated to current valide names by GNVerifier.\n",
    "gnrd_results = {}\n",
    "gnrd_verifier = {} #holds the names that were updated by GNVerifier\n",
    "tot_words = {}\n",
    "for p in packages:\n",
    "    gnrd_names = []\n",
    "    if p != '133':\n",
    "        [json_file] = [x for x in os.listdir('dryad-paper/' + p) if x.endswith(\".json\")]\n",
    "        [csv_file] = [x for x in os.listdir('dryad-paper/' + p) if x.endswith(\".csv\")]\n",
    "        jdata = open('dryad-paper/' + p + '/' + json_file,'r')\n",
    "        result = json.load(jdata)\n",
    "        metadata = result['metadata']\n",
    "        total_words = metadata['totalWords']\n",
    "        cdata = open('dryad-paper/' + p + '/' + csv_file,'r')\n",
    "        names = []\n",
    "        next(cdata)\n",
    "        for line in cdata:\n",
    "            row = line.split(',')\n",
    "            names.append(row[2])\n",
    "        gnrd_results[p] = names\n",
    "        tot_words[p] = total_words\n",
    "        json_names = result['names']\n",
    "        matches = []\n",
    "        #This loop looks for names updated by GNVerifier. We are assuming that a name has been updated\n",
    "        #if the matchType = Exact and isSynonym = True. matchType = NoMatch is given for abbreviations.\n",
    "        for n in json_names:\n",
    "            verbatim_name = n['verbatim']\n",
    "            match_type = n['verification']['matchType']\n",
    "            #print(p)\n",
    "            if match_type == 'NoMatch':\n",
    "                continue\n",
    "            synonym = n['verification']['bestResult']['isSynonym']\n",
    "            if match_type == 'Exact' and synonym == True:\n",
    "                matches.append(verbatim_name)\n",
    "        matches = set(matches)\n",
    "        gnrd_verifier[p] = matches\n",
    "print('completed successfully')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the dictionary for the human annotator data\n",
    "annotator_results = {}\n",
    "for p in packages:\n",
    "    annotator_results[p]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed successfully\n"
     ]
    }
   ],
   "source": [
    "#Read the file that contains the names found by the human annotators. Go over every row of the file and create a\n",
    "#dictionary using the data package ID number as the key and a list of the name strings as the value.\n",
    "# the name string is in a tuple with the type of string, i.e. scientific or vernacular name\n",
    "annotation_file.seek(0)\n",
    "next(annotation_file)\n",
    "for line in annotation_file:\n",
    "    line = line.strip()\n",
    "    row = line.split('\\t')\n",
    "    source_type = row[2]\n",
    "    if source_type == 'data':\n",
    "        continue\n",
    "    else:\n",
    "        string = row[0]\n",
    "        data_package = row[1]\n",
    "        source = row[3]\n",
    "        string_type = row[4]\n",
    "        ls = annotator_results[data_package]\n",
    "        ls.append(tuple([string,string_type]))\n",
    "        annotator_results[data_package] = ls\n",
    "print('completed successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's compare the list of names returned by GNRD with the list of names returned by the annotators\n",
    "#for now, let's ignore the vernacular names in the annotator data\n",
    "#performance metrics for each document are returned in results.tsv\n",
    "#false positives and false negatives are returned in errors.txt\n",
    "\n",
    "error_file = open('errors.txt','w')\n",
    "error_file.write('data_package' + '\\t' + 'name' + '\\t' + 'error_type' + '\\n')\n",
    "\n",
    "df = pd.DataFrame(columns=['data_package','true_positives','false_positives','false_negatives','returned_results','annotator_results','precision',\n",
    "                           'recall','F1','total_words'])\n",
    "\n",
    "for p in packages:\n",
    "    #grab the list for the data package from the gnrd results and the annotator results.\n",
    "    #separate the name strings from the odds value in the gnrd list and the string type in the annotator list\n",
    "    gnrd = gnrd_results[p] #name string and odds value\n",
    "    human = annotator_results[p] #name string and string type\n",
    "    gnrd_set = set(gnrd)\n",
    "    human_string = []\n",
    "    for n,s in human:\n",
    "        if s != 'vernacular': #lets ignore vernacular names for the moment\n",
    "            if n.isupper() == True:\n",
    "                n = n.title()\n",
    "            human_string.append(n)\n",
    "    human_set = set(human_string)\n",
    "    #now we have a set of name strings for gnrd and a set for the annotators\n",
    "    #let's compare them\n",
    "    g = len(gnrd_set) #total strings returned by GNRD\n",
    "    h = len(human_set) #total strings returned by annotator\n",
    "    overlap_set = gnrd_set.intersection(human_set) #this is the set of strings that are in the gnrd and annotator lists\n",
    "    o = len(overlap_set)\n",
    "    gnrd_only = gnrd_set.difference(human_set) #what is in gnrd list that is not in annotator list - false positives\n",
    "    human_only = human_set.difference(gnrd_set) #what is in annotator list that is not in gnrd list - false negatives\n",
    "    for x in gnrd_only:\n",
    "        error_file.write(p + '\\t' + x + '\\t' + 'false positive' + '\\n')\n",
    "    for y in human_only:\n",
    "        error_file.write(p + '\\t' + y + '\\t' + 'false negative' + '\\n')\n",
    "    go = len(gnrd_only)\n",
    "    ho = len(human_only)\n",
    "    if go + o == g and ho + o == h: #adding a sanity check\n",
    "        pass\n",
    "    else:\n",
    "        print('problem')\n",
    "    if g == 0 or h == 0:\n",
    "        precision = 'NULL'\n",
    "        recall = 'NULL'\n",
    "        F1 = 'NULL'\n",
    "    else:\n",
    "        precision = o / g\n",
    "        recall = o / h\n",
    "        if precision == 0 and recall == 0:\n",
    "            F1 = 'NULL'\n",
    "        else:\n",
    "            F1 = 2*((precision*recall)/(precision+recall))\n",
    "    #print(df)\n",
    "    y = {'data_package':p,'true_positives':o,'false_positives':go,'false_negatives':ho,'returned_results':g,'annotator_results':h,\n",
    "                    'precision':precision,'recall':recall,'F1':F1,'total_words':tot_words[p]}\n",
    "    #print(y)\n",
    "    df = df.append(y,ignore_index=True)\n",
    "df.to_csv('results.tsv', sep = '\\t')\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives 7952\n",
      "Returned Results 8691\n",
      "Annotator Results 9753\n",
      "Total Words 1562799\n",
      "False Positives 739\n",
      "False Negatives 1801\n"
     ]
    }
   ],
   "source": [
    "#Now we have a dataframe that contains performance data for each pdf \n",
    "#let's calculate performance overall\n",
    "TOT = df.sum(axis=0)\n",
    "TP = TOT.iloc[1]\n",
    "RR = TOT.iloc[4]\n",
    "AR = TOT.iloc[5]\n",
    "TW = TOT.iloc[6]\n",
    "FP = TOT.iloc[2]\n",
    "FN = TOT.iloc[3]\n",
    "print('True Positives ' + str(TP))\n",
    "print('Returned Results ' + str(RR))\n",
    "print('Annotator Results ' + str(AR))\n",
    "print('Total Words ' + str(TW))\n",
    "print('False Positives ' + str(FP))\n",
    "print('False Negatives ' + str(FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8622858382129691\n",
      "precision is 0.9149695086871477\n",
      "recall is 0.8153388700912539\n"
     ]
    }
   ],
   "source": [
    "precision = TP / RR\n",
    "recall = TP / AR\n",
    "F1 = 2*((precision*recall)/(precision+recall))\n",
    "print(F1)\n",
    "print('precision is ' + str(precision))\n",
    "print('recall is ' + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1254\n"
     ]
    }
   ],
   "source": [
    "#this counts and returns the number of names that were updated by GNVerifier.\n",
    "tot_v = 0\n",
    "for k,v in gnrd_verifier.items():\n",
    "    y = len(v)\n",
    "    tot_v = tot_v + y\n",
    "    #print(k + ' ' + str(y))\n",
    "print(tot_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
