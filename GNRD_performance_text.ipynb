{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import all the libraries we need\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#Get a list of all the folders. The name of the folder is also the id number for the data package. Each folder\n",
    "#contains the text of the pdf as a txt file and the json result from GNRD.\n",
    "packages = []\n",
    "annotation_file = open('dryad_results.txt', 'r')\n",
    "next(annotation_file)\n",
    "for line in annotation_file:\n",
    "    row = line.split('\\t')\n",
    "    data_package = row[1]\n",
    "    if data_package in packages:\n",
    "        pass\n",
    "    else:\n",
    "        packages.append(data_package)\n",
    "#packages = next(os.walk('pdf_text'))[1]\n",
    "packages.remove('133')\n",
    "print(len(packages))\n",
    "'110' in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate over all the folders and grab the json results from each. From the json pick out the name that\n",
    "#GNRD found.\n",
    "gnrd_results = {}\n",
    "tot_words = {}\n",
    "for p in packages:\n",
    "    gnrd_names = []\n",
    "    if p != '133':\n",
    "        [json_file] = [x for x in os.listdir('dryad-paper/' + p) if x.endswith(\".json\")]\n",
    "        [csv_file] = [x for x in os.listdir('dryad-paper/' + p) if x.endswith(\".csv\")]\n",
    "        jdata = open('dryad-paper/' + p + '/' + json_file,'r')\n",
    "        result = json.load(jdata)\n",
    "        metadata = result['metadata']\n",
    "        total_words = metadata['totalWords']\n",
    "        cdata = open('dryad-paper/' + p + '/' + csv_file,'r')\n",
    "        names = []\n",
    "        for line in cdata:\n",
    "            row = line.split(',')\n",
    "            names.append(row[2])\n",
    "        gnrd_results[p] = names\n",
    "        tot_words[p] = total_words\n",
    "#print(gnrd_results['350'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the dictionary for the human annotator data\n",
    "annotator_results = {}\n",
    "for p in packages:\n",
    "    annotator_results[p]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed successfully\n"
     ]
    }
   ],
   "source": [
    "#Read the file that contains the names found by the human annotators. Go over every row of the file and create a\n",
    "#dictionary using the data package ID number as the key and a list of the name strings as the value.\n",
    "# the name string is in a tuple with the type of string, i.e. scientific or vernacular name\n",
    "annotation_file.seek(0)\n",
    "next(annotation_file)\n",
    "for line in annotation_file:\n",
    "    row = line.split('\\t')\n",
    "    string = row[0]\n",
    "    data_package = row[1]\n",
    "    source_type = row[2]\n",
    "    source = row[3]\n",
    "    string_type = row[6]\n",
    "    file_type = row[7]#this is wrong for the publication files\n",
    "    if source_type == 'data' or source == 'GNRD_1':\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            ls = annotator_results[data_package]\n",
    "        except KeyError:\n",
    "            print('possible missing data package')\n",
    "            print(row)\n",
    "        ls.append(tuple([string,string_type]))\n",
    "        annotator_results[data_package] = ls\n",
    "print('completed successfully')\n",
    "#print(annotator_results['350'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    data_package true_positives returned_results annotator_results precision  \\\n",
      "0              2            104              109               106  0.954128   \n",
      "1              6              0                1                 0      NULL   \n",
      "2             12              0                2                 0      NULL   \n",
      "3             18              5                6                52  0.833333   \n",
      "4             22            147              150               151      0.98   \n",
      "..           ...            ...              ...               ...       ...   \n",
      "214         1480             48               50                52      0.96   \n",
      "215         1502              5                6                 5  0.833333   \n",
      "216         1508              8               10                 8       0.8   \n",
      "217         1519              3                6                 3       0.5   \n",
      "218         1523              0               16                 0      NULL   \n",
      "\n",
      "       recall        F1 total_words  \n",
      "0    0.981132  0.967442        7020  \n",
      "1        NULL      NULL        3637  \n",
      "2        NULL      NULL        6530  \n",
      "3    0.096154  0.172414        3037  \n",
      "4     0.97351  0.976744        9253  \n",
      "..        ...       ...         ...  \n",
      "214  0.923077  0.941176        6711  \n",
      "215       1.0  0.909091        3769  \n",
      "216       1.0  0.888889        8205  \n",
      "217       1.0  0.666667        7782  \n",
      "218      NULL      NULL        8626  \n",
      "\n",
      "[219 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#Let's compare the list of names returned by GNRD with the list of names returned by the annotators\n",
    "#for now, let's ignore the vernacular names in the annotator data\n",
    "\n",
    "error_file = open('errors.txt','a')\n",
    "error_file.write('data_package' + '\\t' + 'name' + '\\t' + 'error_type' + '\\n')\n",
    "\n",
    "df = pd.DataFrame(columns=['data_package','true_positives','returned_results','annotator_results','precision',\n",
    "                           'recall','F1','total_words'])\n",
    "\n",
    "for p in packages:\n",
    "    #grab the list for the data package from the gnrd results and the annotator results.\n",
    "    #separate the name strings from the odds value in the gnrd list and the string type in the annotator list\n",
    "    gnrd = gnrd_results[p] #name string and odds value\n",
    "    human = annotator_results[p] #name string and string type\n",
    "    gnrd_set = set(gnrd)\n",
    "    human_string = []\n",
    "    for n,s in human:\n",
    "        if s != 'vernacular': #lets ignore vernacular names for the moment\n",
    "            if n.isupper() == True:\n",
    "                n = n.title()\n",
    "            human_string.append(n)\n",
    "    human_set = set(human_string)\n",
    "    #now we have a set of name strings for gnrd and a set for the annotators\n",
    "    #let's compare them\n",
    "    g = len(gnrd_set) #total strings returned by GNRD\n",
    "    h = len(human_set) #total strings returned by annotator\n",
    "    overlap_set = gnrd_set.intersection(human_set) #this is the set of strings that are in the gnrd and annotator lists\n",
    "    o = len(overlap_set)\n",
    "    gnrd_only = gnrd_set.difference(human_set) #what is in gnrd list that is not in annotator list - false positives\n",
    "    human_only = human_set.difference(gnrd_set) #what is in annotator list that is not in gnrd list - false negatives\n",
    "    for x in gnrd_only:\n",
    "        error_file.write(p + '\\t' + x + '\\t' + 'false positive' + '\\n')\n",
    "    for y in human_only:\n",
    "        error_file.write(p + '\\t' + y + '\\t' + 'false negative' + '\\n')\n",
    "    go = len(gnrd_only)\n",
    "    ho = len(human_only)\n",
    "    if go + o == g and ho + o == h: #adding a sanity check\n",
    "        pass\n",
    "    else:\n",
    "        print('problem')\n",
    "    if g == 0 or h == 0:\n",
    "        precision = 'NULL'\n",
    "        recall = 'NULL'\n",
    "        F1 = 'NULL'\n",
    "    else:\n",
    "        precision = o / g\n",
    "        recall = o / h\n",
    "        if precision == 0 and recall == 0:\n",
    "            F1 = 'NULL'\n",
    "        else:\n",
    "            F1 = 2*((precision*recall)/(precision+recall))\n",
    "    #print(df)\n",
    "    y = {'data_package':p,'true_positives':o,'returned_results':g,'annotator_results':h,\n",
    "                    'precision':precision,'recall':recall,'F1':F1,'total_words':tot_words[p]}\n",
    "    df = df.append(y,ignore_index=True)\n",
    "df.to_csv('results.tsv', sep = '\\t')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives 7952\n",
      "Returned Results 8929\n",
      "Annotator Results 9753\n",
      "Total Words 1589065\n"
     ]
    }
   ],
   "source": [
    "#Now we have a dataframe that contains performance data for each pdf \n",
    "#let's calculate performance overall\n",
    "TOT = df.sum(axis=0)\n",
    "TP = TOT.iloc[1]\n",
    "RR = TOT.iloc[2]\n",
    "AR = TOT.iloc[3]\n",
    "TW = TOT.iloc[4]\n",
    "print('True Positives ' + str(TP))\n",
    "print('Returned Results ' + str(RR))\n",
    "print('Annotator Results ' + str(AR))\n",
    "print('Total Words ' + str(TW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8513007172679585\n",
      "precision is 0.8905812520998992\n",
      "recall is 0.8153388700912539\n"
     ]
    }
   ],
   "source": [
    "precision = TP / RR\n",
    "recall = TP / AR\n",
    "F1 = 2*((precision*recall)/(precision+recall))\n",
    "print(F1)\n",
    "print('precision is ' + str(precision))\n",
    "print('recall is ' + str(recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
